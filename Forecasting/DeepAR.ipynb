{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "quG875DkrHgo"
      },
      "outputs": [],
      "source": [
        "!pip install autogluon.timeseries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XrB0NLjyrJ6A"
      },
      "outputs": [],
      "source": [
        "!pip install torch==1.13.1+cu117 torchvision==0.14.1+cu117 torchtext==0.14.1 torchaudio==0.13.1 torchdata==0.5.1 --extra-index-url https://download.pytorch.org/whl/cu117"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AaOqJEJerCAs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from autogluon.timeseries import TimeSeriesDataFrame, TimeSeriesPredictor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_cAJy0XKrGoW"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('three input.csv')\n",
        "train_data = data[['timestamp','Temp_Box','Temp','item_id']]\n",
        "train_data.tail(240)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49jfGh1mrPNo"
      },
      "outputs": [],
      "source": [
        "train_data['timestamp'] = train_data['timestamp'].astype('datetime64')\n",
        "train_data_partial_per_item = []\n",
        "train_data_item_id = pd.DataFrame(train_data).groupby('item_id')\n",
        "for i,j in train_data_item_id:\n",
        "    train_data_partial_per_item.append(pd.DataFrame(j[:72]).set_index(['item_id','timestamp']))\n",
        "    #print(train_data_partial_per_item)\n",
        "train_data_partial = TimeSeriesDataFrame(pd.concat(train_data_partial_per_item))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZYVOKPtZzRb"
      },
      "outputs": [],
      "source": [
        "train_data_partial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ziVB8aGtrRL-"
      },
      "outputs": [],
      "source": [
        "import autogluon.core as ag\n",
        "while len(train_data_partial) < len(train_data):\n",
        "  if len(train_data_partial.loc[1]) < 49:\n",
        "    pred_len = 1\n",
        "  elif len(train_data_partial.loc[1]) >= 49 and len(train_data_partial.loc[1]) < 72:\n",
        "    pred_len = 23\n",
        "  elif len(train_data_partial.loc[1]) >= 72:\n",
        "    pred_len =  24\n",
        "  elif len(train_data_partial.loc[1]) == 240:\n",
        "    break\n",
        "\n",
        "  predictor = TimeSeriesPredictor(\n",
        "      prediction_length= pred_len,\n",
        "      target=\"Temp\",\n",
        "      known_covariates_names=[\"Temp_Box\"],\n",
        "      eval_metric=\"RMSE\",\n",
        "      ignore_time_index = True\n",
        "      ).fit(train_data_partial,\n",
        "            #hyperparameters = {\"DeepAR\" : {\"hidden_size\": ag.space.Int(20, 100),}},\n",
        "            #hyperparameter_tune_kwargs=\"auto\",\n",
        "            hyperparameters = {\"DeepAR\" : {}}\n",
        "        )\n",
        "\n",
        "  known_covariates_per_item = []\n",
        "  for i,j in train_data_item_id:\n",
        "    known_covariate = pd.DataFrame(j[len(train_data_partial.loc[1]): len(train_data_partial.loc[1])+pred_len]).set_index(['item_id','timestamp'])\n",
        "    #known_covariate['Temp_Easy'] = known_covariate['Temp_Box']\n",
        "    known_covariates_per_item.append(pd.DataFrame(known_covariate[['Temp_Box']]))\n",
        "  known_covariates = TimeSeriesDataFrame(pd.concat(known_covariates_per_item))\n",
        "  predict_data = predictor.predict(train_data_partial, known_covariates = known_covariates)\n",
        "  new_train_data_per_item = []\n",
        "  for i in range(len(known_covariates_per_item)):\n",
        "    predicted_data_chunk = pd.DataFrame(predict_data[['mean']].values[i*len(known_covariates_per_item[i]):(i+1)*len(known_covariates_per_item[i])], index = pd.DataFrame(known_covariates_per_item[i]).index, columns = [\"Temp\"])\n",
        "    together =  pd.concat([pd.DataFrame(known_covariates_per_item[i]), predicted_data_chunk], axis = 1)\n",
        "    if len(train_data_partial.loc[1]) == 72:\n",
        "      together = pd.concat([train_data_partial_per_item[i], together], axis = 0)\n",
        "    else:\n",
        "      idx = together.index[0][0]\n",
        "      together = pd.concat([train_data_partial.loc[together.index[0][0]], together.loc[together.index[0][0]]], axis = 0)\n",
        "      together.reset_index(inplace = True)\n",
        "      together['item_id'] = idx\n",
        "      together = together.set_index(['item_id','timestamp'])\n",
        "    new_train_data_per_item.append(together)\n",
        "\n",
        "  train_data_partial = TimeSeriesDataFrame(pd.concat(new_train_data_per_item))\n",
        "train_data_partial"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}